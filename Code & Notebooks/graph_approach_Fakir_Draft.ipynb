{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d514801b-cb8f-49c6-85c5-84a49a687ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:29.673181Z",
     "iopub.status.busy": "2023-01-21T05:33:29.672856Z",
     "iopub.status.idle": "2023-01-21T05:33:34.541538Z",
     "shell.execute_reply": "2023-01-21T05:33:34.540721Z",
     "shell.execute_reply.started": "2023-01-21T05:33:29.673118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# !pip install tensorflow\n",
    "# !pip install  spacy\n",
    "# !pip install tqdm\n",
    "# !pip install plotly\n",
    "!pip install jupyter-black\n",
    "!pip install imblearn\n",
    "\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab47875-d7b8-467e-9f9a-824abb3b9105",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92068b-ba2c-4f7d-b774-e77d9743c4f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3f4560-096a-4342-9371-ccb1bbaef8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:34.543278Z",
     "iopub.status.busy": "2023-01-21T05:33:34.543055Z",
     "iopub.status.idle": "2023-01-21T05:33:35.181301Z",
     "shell.execute_reply": "2023-01-21T05:33:35.180672Z",
     "shell.execute_reply.started": "2023-01-21T05:33:34.543255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5fcdd3-4daf-4942-bdec-989e2c169e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.182709Z",
     "iopub.status.busy": "2023-01-21T05:33:35.182155Z",
     "iopub.status.idle": "2023-01-21T05:33:35.250693Z",
     "shell.execute_reply": "2023-01-21T05:33:35.249924Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.182686Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a331634-a658-4862-acd5-cb498ef7064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.252202Z",
     "iopub.status.busy": "2023-01-21T05:33:35.251988Z",
     "iopub.status.idle": "2023-01-21T05:33:35.257709Z",
     "shell.execute_reply": "2023-01-21T05:33:35.257056Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.252183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44121573-5f12-45de-9286-3e7c4d79050d",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba141e71-43b6-4129-8477-8d5160f317dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.260142Z",
     "iopub.status.busy": "2023-01-21T05:33:35.259674Z",
     "iopub.status.idle": "2023-01-21T05:33:35.302693Z",
     "shell.execute_reply": "2023-01-21T05:33:35.301969Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.260123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "# Read sequences\n",
    "sequences = list()\n",
    "with open(path + \"sequences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        sequences.append(line[:-1])\n",
    "\n",
    "# Split data into training and test sets\n",
    "sequences_train = list()\n",
    "sequences_test = list()\n",
    "proteins_test = list()\n",
    "train_target = list()\n",
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            sequences_test.append(sequences[i])\n",
    "        else:\n",
    "            sequences_train.append(sequences[i])\n",
    "            train_target.append(int(t[1][:-1]))\n",
    "\n",
    "sequences_train = np.array(sequences_train)\n",
    "train_target = np.array(train_target)\n",
    "sequences_test = np.array(sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d37beaf-7bc8-4804-b9e7-c69442ddd119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.303590Z",
     "iopub.status.busy": "2023-01-21T05:33:35.303396Z",
     "iopub.status.idle": "2023-01-21T05:33:35.315326Z",
     "shell.execute_reply": "2023-01-21T05:33:35.314541Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.303570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"seq\": sequences_train, \"target\": train_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e226940-ef41-4472-81cf-aa6197057635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.316834Z",
     "iopub.status.busy": "2023-01-21T05:33:35.316306Z",
     "iopub.status.idle": "2023-01-21T05:33:35.326343Z",
     "shell.execute_reply": "2023-01-21T05:33:35.325012Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.316810Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen = pd.DataFrame({\"seq\": sequences_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50ec40a-3d0e-4cb5-9272-18352a1dd755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.327310Z",
     "iopub.status.busy": "2023-01-21T05:33:35.327080Z",
     "iopub.status.idle": "2023-01-21T05:33:35.922998Z",
     "shell.execute_reply": "2023-01-21T05:33:35.922224Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.327290Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.target.hist(bins=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd51e667-f8c5-4945-8da1-fb1460e584ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.924890Z",
     "iopub.status.busy": "2023-01-21T05:33:35.924120Z",
     "iopub.status.idle": "2023-01-21T05:33:35.996175Z",
     "shell.execute_reply": "2023-01-21T05:33:35.995301Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.924853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47095820b4948cfa4326a42b7fdbd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf9beba5a64048b5cb013247dc0b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.14279869067104\n",
      "mean 258.14279869067104 and std is 162.24346887570542\n"
     ]
    }
   ],
   "source": [
    "mean_carr = np.mean(data.seq.progress_apply(len))\n",
    "std_carr = np.std(data.seq.progress_apply(len))\n",
    "print(mean_carr)\n",
    "print(\"mean\", mean_carr, \"and std is\", std_carr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f8a40-d81d-4c7a-ab87-6cf914da9fc4",
   "metadata": {},
   "source": [
    "We notice that the target isn't balanced, so we will take that into consideration by :\n",
    "- adding sample weight in logistic regression and the other models that supports weight to impact directly the loss function\n",
    "- we can make an oversampling using duplication which is poor or using smote (that add some guassian noise )\n",
    "- we can make an undersampling by reducing the number of majority class samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1968a-5a81-4861-a099-c1346ec96ddc",
   "metadata": {},
   "source": [
    "### Important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a916f1a-317a-402a-9ec6-db0923a97dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:35.997616Z",
     "iopub.status.busy": "2023-01-21T05:33:35.997364Z",
     "iopub.status.idle": "2023-01-21T05:33:36.007474Z",
     "shell.execute_reply": "2023-01-21T05:33:36.006552Z",
     "shell.execute_reply.started": "2023-01-21T05:33:35.997592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x - np.max(x))\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "\n",
    "softmax_vect = np.vectorize(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8af066c-582f-4792-abaa-5f32e32f2ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.009078Z",
     "iopub.status.busy": "2023-01-21T05:33:36.008584Z",
     "iopub.status.idle": "2023-01-21T05:33:36.019523Z",
     "shell.execute_reply": "2023-01-21T05:33:36.018737Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.009038Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted multi-class log loss\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def weighted_mc_log_loss(y_true, y_pred, y_pred_proba):\n",
    "    loss = log_loss(y_true, y_pred_proba, labels=np.unique(y_true))\n",
    "    accuracy = round((y_true == y_pred).sum() / len(y_true) * 100, 2)\n",
    "    return print(f\"{loss = } and accuracy {accuracy = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00dc7a6f-c7d5-4cbb-b0a7-539e42eeeb2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.020863Z",
     "iopub.status.busy": "2023-01-21T05:33:36.020637Z",
     "iopub.status.idle": "2023-01-21T05:33:36.035391Z",
     "shell.execute_reply": "2023-01-21T05:33:36.034557Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.020844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba):\n",
    "    # Write predictions to a file\n",
    "    with open(\"../Submissions/sample_submission.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d628810-a306-488c-b82b-cf58036532fa",
   "metadata": {},
   "source": [
    "# using structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be017f7-0fea-45fd-ae55-1f00d2c60aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.036507Z",
     "iopub.status.busy": "2023-01-21T05:33:36.036259Z",
     "iopub.status.idle": "2023-01-21T05:33:36.608178Z",
     "shell.execute_reply": "2023-01-21T05:33:36.607403Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.036487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc2aae1-32bf-4772-8bb2-b001267ecc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.612434Z",
     "iopub.status.busy": "2023-01-21T05:33:36.611690Z",
     "iopub.status.idle": "2023-01-21T05:33:36.648805Z",
     "shell.execute_reply": "2023-01-21T05:33:36.647731Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.612411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function that loads graphs\n",
    "    \"\"\"\n",
    "    graph_indicator = np.loadtxt(path + \"graph_indicator.txt\", dtype=np.int64)\n",
    "    _, graph_size = np.unique(graph_indicator, return_counts=True)\n",
    "\n",
    "    edges = np.loadtxt(path + \"edgelist.txt\", dtype=np.int64, delimiter=\",\")\n",
    "    edges_inv = np.vstack((edges[:, 1], edges[:, 0]))\n",
    "    edges = np.vstack((edges, edges_inv.T))\n",
    "    s = edges[:, 0] * graph_indicator.size + edges[:, 1]\n",
    "    idx_sort = np.argsort(s)\n",
    "    edges = edges[idx_sort, :]\n",
    "    edges, idx_unique = np.unique(edges, axis=0, return_index=True)\n",
    "    A = sp.csr_matrix(\n",
    "        (np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "        shape=(graph_indicator.size, graph_indicator.size),\n",
    "    )\n",
    "\n",
    "    x = np.loadtxt(path + \"node_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.loadtxt(path + \"edge_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.vstack((edge_attr, edge_attr))\n",
    "    edge_attr = edge_attr[idx_sort, :]\n",
    "    edge_attr = edge_attr[idx_unique, :]\n",
    "\n",
    "    adj = []\n",
    "    features = []\n",
    "    edge_features = []\n",
    "    idx_n = 0\n",
    "    idx_m = 0\n",
    "    for i in range(graph_size.size):\n",
    "        adj.append(A[idx_n : idx_n + graph_size[i], idx_n : idx_n + graph_size[i]])\n",
    "        edge_features.append(edge_attr[idx_m : idx_m + adj[i].nnz, :])\n",
    "        features.append(x[idx_n : idx_n + graph_size[i], :])\n",
    "        idx_n += graph_size[i]\n",
    "        idx_m += adj[i].nnz\n",
    "\n",
    "    return adj, features, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a06e3c3-1719-45bc-b17d-57424bbe290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.654813Z",
     "iopub.status.busy": "2023-01-21T05:33:36.654621Z",
     "iopub.status.idle": "2023-01-21T05:33:36.671648Z",
     "shell.execute_reply": "2023-01-21T05:33:36.671011Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.654794Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_adjacency(A):\n",
    "    \"\"\"\n",
    "    Function that normalizes an adjacency matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    A += sp.identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D = sp.diags(inv_degs)\n",
    "    A_normalized = D.dot(A)\n",
    "\n",
    "    return A_normalized\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"\n",
    "    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n",
    "    \"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55ecfc7-9ea9-4a15-83e5-18128cabacee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:33:36.674473Z",
     "iopub.status.busy": "2023-01-21T05:33:36.674298Z",
     "iopub.status.idle": "2023-01-21T05:34:04.327217Z",
     "shell.execute_reply": "2023-01-21T05:34:04.326414Z",
     "shell.execute_reply.started": "2023-01-21T05:33:36.674454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load graphs\n",
    "adj, features, edge_features = load_data()\n",
    "\n",
    "# Normalize adjacency matrices\n",
    "adj = [normalize_adjacency(A) for A in adj]\n",
    "\n",
    "# Split data into training and test sets\n",
    "adj_train = list()\n",
    "features_train = list()\n",
    "edge_features_train = list()\n",
    "y_train = list()\n",
    "adj_test = list()\n",
    "features_test = list()\n",
    "edge_features_test = list()\n",
    "proteins_test = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03e358d-2664-4d0f-9450-71e561e6bf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:04.330564Z",
     "iopub.status.busy": "2023-01-21T05:34:04.330384Z",
     "iopub.status.idle": "2023-01-21T05:34:04.351212Z",
     "shell.execute_reply": "2023-01-21T05:34:04.350284Z",
     "shell.execute_reply.started": "2023-01-21T05:34:04.330544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            adj_test.append(adj[i])\n",
    "            features_test.append(features[i])\n",
    "            edge_features_test.append(edge_features[i])\n",
    "        else:\n",
    "            adj_train.append(adj[i])\n",
    "            features_train.append(features[i])\n",
    "            edge_features_train.append(edge_features[i])\n",
    "            y_train.append(int(t[1][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b944a73a-0dbb-4772-bcf3-ceb810adb974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:04.354519Z",
     "iopub.status.busy": "2023-01-21T05:34:04.354339Z",
     "iopub.status.idle": "2023-01-21T05:34:04.358263Z",
     "shell.execute_reply": "2023-01-21T05:34:04.357632Z",
     "shell.execute_reply.started": "2023-01-21T05:34:04.354500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adj_train = adj_train[:50].copy()\n",
    "# features_train = features_train[:50].copy()\n",
    "# edge_features_train = edge_features_train[:50].copy()\n",
    "# y_train = y_train[:50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b379b1a-0af4-475a-86fa-a226514fc21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:04.361039Z",
     "iopub.status.busy": "2023-01-21T05:34:04.360852Z",
     "iopub.status.idle": "2023-01-21T05:34:32.510022Z",
     "shell.execute_reply": "2023-01-21T05:34:32.509401Z",
     "shell.execute_reply.started": "2023-01-21T05:34:04.361021Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib as joblib\n",
    "\n",
    "features_train = joblib.load(\"new_features.sav\")\n",
    "features_test = joblib.load(\"new_features_test.sav\")\n",
    "n_input = features_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f496844-40df-46d0-b722-4de54f7b9ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:32.512623Z",
     "iopub.status.busy": "2023-01-21T05:34:32.512454Z",
     "iopub.status.idle": "2023-01-21T05:34:32.515943Z",
     "shell.execute_reply": "2023-01-21T05:34:32.515442Z",
     "shell.execute_reply.started": "2023-01-21T05:34:32.512605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# data_pca = np.concatenate(features_train, axis=0)\n",
    "\n",
    "# pca = PCA(n_components=50)\n",
    "# pca.fit(data_pca)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)\n",
    "\n",
    "# print(pca.explained_variance_ratio_.sum())\n",
    "\n",
    "# print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f8cac3-77ce-4978-baea-756e66287c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:32.518248Z",
     "iopub.status.busy": "2023-01-21T05:34:32.518086Z",
     "iopub.status.idle": "2023-01-21T05:34:32.521516Z",
     "shell.execute_reply": "2023-01-21T05:34:32.520981Z",
     "shell.execute_reply.started": "2023-01-21T05:34:32.518231Z"
    }
   },
   "outputs": [],
   "source": [
    "# features_train = [pca.transform(i) for i in features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28b34880-1507-4f1e-9695-80e14652d2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:32.523924Z",
     "iopub.status.busy": "2023-01-21T05:34:32.523713Z",
     "iopub.status.idle": "2023-01-21T05:34:39.188017Z",
     "shell.execute_reply": "2023-01-21T05:34:39.187424Z",
     "shell.execute_reply.started": "2023-01-21T05:34:32.523905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def get_Data(adj_train, features_train, edge_features_train, y_train):\n",
    "    data = []\n",
    "    for i in range(len(features_train)):\n",
    "        adj_t = torch.tensor(adj_train[i].todense())\n",
    "        edge_index = adj_t.nonzero().t().contiguous()\n",
    "        x = torch.tensor(features_train[i]).float()\n",
    "        edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y_train[i]))\n",
    "    return data\n",
    "\n",
    "\n",
    "data_obj = get_Data(adj_train, features_train, edge_features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794e1c52-cc8a-476b-a838-216df7e94166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:39.191479Z",
     "iopub.status.busy": "2023-01-21T05:34:39.190857Z",
     "iopub.status.idle": "2023-01-21T05:34:40.261094Z",
     "shell.execute_reply": "2023-01-21T05:34:40.260447Z",
     "shell.execute_reply.started": "2023-01-21T05:34:39.191455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Data_pred(adj_train, features_train, edge_features_train):\n",
    "    data = []\n",
    "    for i in range(len(features_train)):\n",
    "        adj_t = torch.tensor(adj_train[i].todense())\n",
    "        edge_index = adj_t.nonzero().t().contiguous()\n",
    "        x = torch.tensor(features_train[i]).float()\n",
    "        edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr))\n",
    "    return data\n",
    "\n",
    "\n",
    "data_obj_pred = get_Data_pred(adj_test, features_test, edge_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae53b548-e3e9-4d1a-b8c0-934ac088886a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:40.265625Z",
     "iopub.status.busy": "2023-01-21T05:34:40.263900Z",
     "iopub.status.idle": "2023-01-21T05:34:40.274491Z",
     "shell.execute_reply": "2023-01-21T05:34:40.273535Z",
     "shell.execute_reply.started": "2023-01-21T05:34:40.265595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 4399\n",
      "Number of test graphs: 489\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_obj[: int(len(data_obj) * 9 / 10)]\n",
    "test_dataset = data_obj[int(len(data_obj) * 9 / 10) :]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba173eb-176a-4f18-9a29-e33c980ac76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:40.278153Z",
     "iopub.status.busy": "2023-01-21T05:34:40.277850Z",
     "iopub.status.idle": "2023-01-21T05:34:40.289391Z",
     "shell.execute_reply": "2023-01-21T05:34:40.288595Z",
     "shell.execute_reply.started": "2023-01-21T05:34:40.278122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "pred_loader = DataLoader(data_obj_pred, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c972da03-e02c-4124-bd1f-2e027e1f31b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:40.292488Z",
     "iopub.status.busy": "2023-01-21T05:34:40.292306Z",
     "iopub.status.idle": "2023-01-21T05:34:40.296230Z",
     "shell.execute_reply": "2023-01-21T05:34:40.295494Z",
     "shell.execute_reply.started": "2023-01-21T05:34:40.292465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neigh_loader = []\n",
    "# for i in range(len(train_dataset)):\n",
    "#     loader = NeighborSampler(\n",
    "#         train_dataset[i].edge_index, sizes=[30], batch_size=32, shuffle=True\n",
    "#     )\n",
    "#     sampled_data = next(iter(loader))\n",
    "#     neigh_loader.append(sampled_data)\n",
    "# train_loader = DataLoader(neigh_loader, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19dbe0be-36d4-47c3-9295-6c152c445943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:40.301679Z",
     "iopub.status.busy": "2023-01-21T05:34:40.301052Z",
     "iopub.status.idle": "2023-01-21T05:34:41.174812Z",
     "shell.execute_reply": "2023-01-21T05:34:41.174185Z",
     "shell.execute_reply.started": "2023-01-21T05:34:40.301657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[7702, 406], edge_index=[2, 138742], edge_attr=[138742, 5], y=[32], batch=[7702], ptr=[33])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[6987, 406], edge_index=[2, 127067], edge_attr=[127067, 5], y=[32], batch=[6987], ptr=[33])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[7683, 406], edge_index=[2, 141669], edge_attr=[141669, 5], y=[32], batch=[7683], ptr=[33])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[9105, 406], edge_index=[2, 171035], edge_attr=[171035, 5], y=[32], batch=[9105], ptr=[33])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[6918, 406], edge_index=[2, 123498], edge_attr=[123498, 5], y=[32], batch=[6918], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    if step < 5:\n",
    "        print(f\"Step {step + 1}:\")\n",
    "        print(\"=======\")\n",
    "        print(f\"Number of graphs in the current batch: {data.num_graphs}\")\n",
    "        print(data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9d7e6-66a9-4808-aef3-35f8d6b2863f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03dd6a35-7b3e-4a5a-a935-e8862ca4ef08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:41.178733Z",
     "iopub.status.busy": "2023-01-21T05:34:41.178536Z",
     "iopub.status.idle": "2023-01-21T05:34:42.517236Z",
     "shell.execute_reply": "2023-01-21T05:34:42.516515Z",
     "shell.execute_reply.started": "2023-01-21T05:34:41.178714Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (layer1): GCNConv(-1, 512)\n",
      "  (layer2): GCNConv(512, 256)\n",
      "  (decoder): Linear(in_features=256, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "num_node_features = features_train[0].shape[1]\n",
    "num_classes = 18\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"GCN\",\n",
    "        hidden_channels=[512, 256, 256],  # [128, 64, 32]\n",
    "        num_heads=[1, 1, 1],  # [1, 1, 1]\n",
    "        dropout=0.2,\n",
    "        n_classes=num_classes,\n",
    "        input_dim=num_node_features,\n",
    "    ):\n",
    "        super(GNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_channels[2]\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == \"GCN\":\n",
    "            self.layer1 = GCNConv(in_channels=-1, out_channels=hidden_channels[0])\n",
    "            self.layer2 = GCNConv(\n",
    "                in_channels=hidden_channels[0], out_channels=hidden_channels[1]\n",
    "            )\n",
    "            # self.layer3 = GCNConv(\n",
    "            #     in_channels=hidden_channels[1], out_channels=hidden_channels[2]\n",
    "            # )\n",
    "            self.decoder = nn.Linear(hidden_channels[1], n_classes)  # [2]\n",
    "\n",
    "        elif model_name == \"GAT\":\n",
    "            self.layer1 = GATConv(\n",
    "                in_channels=-1,\n",
    "                out_channels=hidden_channels[0],\n",
    "                heads=num_heads[0],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer2 = GATConv(\n",
    "                hidden_channels[0] * num_heads[0],\n",
    "                hidden_channels[1],\n",
    "                heads=num_heads[1],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer3 = GATConv(\n",
    "                hidden_channels[1] * num_heads[1],\n",
    "                hidden_channels[2],\n",
    "                heads=1,\n",
    "                edge_dim=5,\n",
    "                concat=False,\n",
    "            )\n",
    "            self.decoder = nn.Linear(hidden_channels[2], n_classes)\n",
    "\n",
    "        elif model_name == \"GraphSAGE\":\n",
    "            self.layer1 = SAGEConv(input_dim, hidden_channels[0], aggr=\"lstm\")\n",
    "            self.layer2 = SAGEConv(hidden_channels[0], hidden_channels[1], aggr=\"lstm\")\n",
    "            self.layer3 = SAGEConv(hidden_channels[1], hidden_channels[2], aggr=\"lstm\")\n",
    "            self.decoder = nn.Linear(hidden_channels[2], n_classes)\n",
    "\n",
    "        # self.decoder = nn.Linear(hidden_channels[2], n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        if self.model_name == \"GAT\":\n",
    "            x = self.layer1(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            x = self.layer2(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            x = self.layer3(x, edge_index, edge_attr)\n",
    "        else:\n",
    "            x = self.layer1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            x = self.layer2(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            # x = self.layer3(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "model = GNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8713497f-8d19-4b0a-aa6c-9f4965b14b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:42.520258Z",
     "iopub.status.busy": "2023-01-21T05:34:42.520027Z",
     "iopub.status.idle": "2023-01-21T05:34:42.526376Z",
     "shell.execute_reply": "2023-01-21T05:34:42.525702Z",
     "shell.execute_reply.started": "2023-01-21T05:34:42.520235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.nn import Linear\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# num_node_features = features_train[0].shape[1]\n",
    "# num_classes = 18\n",
    "\n",
    "\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, hidden_channels):\n",
    "#         super(GCN, self).__init__()\n",
    "#         torch.manual_seed(12345)\n",
    "#         self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "#         self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index, _, batch):\n",
    "#         # 1. Obtain node embeddings\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = self.conv3(x, edge_index)\n",
    "\n",
    "#         # 2. Readout layer\n",
    "#         x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "#         # 3. Apply a final classifier\n",
    "#         # x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.lin(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "# model = GCN(hidden_channels=64).to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6212a50-6ae4-4edf-82b4-caa7770e4b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:34:42.529345Z",
     "iopub.status.busy": "2023-01-21T05:34:42.529123Z",
     "iopub.status.idle": "2023-01-21T05:35:44.697324Z",
     "shell.execute_reply": "2023-01-21T05:35:44.696377Z",
     "shell.execute_reply.started": "2023-01-21T05:34:42.529320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 loss_train: 2.3078 acc_train: 38.5997 loss_val: 2.4192 acc_val: 25.5624\n",
      "Validation Loss Decreased(inf--->2.419173) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 003 loss_train: 2.1171 acc_train: 40.0546 loss_val: 2.5091 acc_val: 26.1759\n",
      "Validation loss increased :(\n",
      "Epoch: 004 loss_train: 1.9987 acc_train: 43.5099 loss_val: 2.1208 acc_val: 36.6053\n",
      "Validation Loss Decreased(2.419173--->2.120836) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 005 loss_train: 1.7643 acc_train: 50.1705 loss_val: 1.9486 acc_val: 42.3313\n",
      "Validation Loss Decreased(2.120836--->1.948615) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 006 loss_train: 1.7031 acc_train: 51.9436 loss_val: 1.9298 acc_val: 43.5583\n",
      "Validation Loss Decreased(1.948615--->1.929757) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 007 loss_train: 1.6566 acc_train: 52.7620 loss_val: 1.7714 acc_val: 45.6033\n",
      "Validation Loss Decreased(1.929757--->1.771425) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 008 loss_train: 1.7027 acc_train: 53.0120 loss_val: 1.8382 acc_val: 46.6258\n",
      "Validation loss increased :(\n",
      "Epoch: 009 loss_train: 1.5959 acc_train: 54.8079 loss_val: 1.7464 acc_val: 49.6933\n",
      "Validation Loss Decreased(1.771425--->1.746365) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 010 loss_train: 1.5664 acc_train: 54.7624 loss_val: 1.7712 acc_val: 48.6708\n",
      "Validation loss increased :(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 408.00 MiB (GPU 0; 15.74 GiB total capacity; 8.32 GiB already allocated; 279.56 MiB free; 14.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m train()\n\u001b[1;32m     41\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[0;32m---> 42\u001b[0m test_acc, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     26\u001b[0m     loader\n\u001b[1;32m     27\u001b[0m ):  \u001b[38;5;66;03m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Use the class with highest probability.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((pred \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39msum())  \u001b[38;5;66;03m# Check against ground-truth labels.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x, edge_index, edge_attr)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/nn/conv/gcn_conv.py:198\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    195\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/nn/conv/message_passing.py:437\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 437\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    439\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/nn/conv/gcn_conv.py:207\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[0;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 408.00 MiB (GPU 0; 15.74 GiB total capacity; 8.32 GiB already allocated; 279.56 MiB free; 14.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# model = GCN(hidden_channels=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(\n",
    "        loader\n",
    "    ):  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        loss += criterion(out, data.y)\n",
    "    return correct / len(loader.dataset) * 100, loss / (\n",
    "        i + 1\n",
    "    )  # Derive ratio of correct predictions. , proba\n",
    "\n",
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "for epoch in range(1, 401):\n",
    "    train()\n",
    "    train_acc, train_loss = test(train_loader)\n",
    "    test_acc, test_loss = test(test_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        # Evaluate model\n",
    "        model.eval()\n",
    "        # val_loss = log_loss(y_val, y_pred_proba, labels=np.unique(y_val))\n",
    "        print(\n",
    "            \"Epoch: {:03d}\".format(epoch + 1),\n",
    "            \"loss_train: {:.4f}\".format(train_loss),\n",
    "            \"acc_train: {:.4f}\".format(train_acc),\n",
    "            \"loss_val: {:.4f}\".format(test_loss),\n",
    "            \"acc_val: {:.4f}\".format(test_acc),\n",
    "        )\n",
    "        if min_val_loss > test_loss:\n",
    "            print(\n",
    "                f\"Validation Loss Decreased({min_val_loss:.6f}--->{test_loss:.6f}) \\t Saving The Model\"\n",
    "            )\n",
    "            min_val_loss = test_loss\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), \"saved_model_esm.pth\")\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Validation loss increased :(\")\n",
    "        # print(f\"Epoch: {epoch:03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73bf9280-d04e-4ce3-8e3b-f4d4198809b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T05:32:45.934881Z",
     "iopub.status.busy": "2023-01-21T05:32:45.934144Z",
     "iopub.status.idle": "2023-01-21T05:32:45.938643Z",
     "shell.execute_reply": "2023-01-21T05:32:45.938073Z",
     "shell.execute_reply.started": "2023-01-21T05:32:45.934853Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0871f74-33ed-4032-b10a-b0c8acd0d090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "81f7788a-8c94-497c-a68f-8dfd90a8ad0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T04:19:38.057262Z",
     "iopub.status.busy": "2023-01-21T04:19:38.056709Z",
     "iopub.status.idle": "2023-01-21T04:19:38.136779Z",
     "shell.execute_reply": "2023-01-21T04:19:38.136045Z",
     "shell.execute_reply.started": "2023-01-21T04:19:38.057238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (layer1): GCNConv(-1, 64)\n",
       "  (layer2): GCNConv(64, 64)\n",
       "  (layer3): GCNConv(64, 64)\n",
       "  (decoder): Linear(in_features=64, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"saved_model_esm.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "800be3ae-319f-4e05-9edb-833c85970b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T04:19:49.118508Z",
     "iopub.status.busy": "2023-01-21T04:19:49.117934Z",
     "iopub.status.idle": "2023-01-21T04:19:49.130750Z",
     "shell.execute_reply": "2023-01-21T04:19:49.130079Z",
     "shell.execute_reply.started": "2023-01-21T04:19:49.118484Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    pred = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, _, data.batch)\n",
    "        out = softmax(out)\n",
    "        pred.append(out.to(\"cpu\").numpy())\n",
    "        # pred.append(out.argmax(dim=1))  # Use the class with highest probability.\n",
    "\n",
    "    return np.concatenate(pred, axis=0)  # Derive ratio of correct predictions. , proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a9c2562d-305c-422f-95a5-44fcc4e6eb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T04:21:50.486787Z",
     "iopub.status.busy": "2023-01-21T04:21:50.486504Z",
     "iopub.status.idle": "2023-01-21T04:21:50.858375Z",
     "shell.execute_reply": "2023-01-21T04:21:50.857734Z",
     "shell.execute_reply.started": "2023-01-21T04:21:50.486767Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = predict(pred_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68761999-08ae-4dab-8747-a82dca5ffb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T04:21:59.663801Z",
     "iopub.status.busy": "2023-01-21T04:21:59.663518Z",
     "iopub.status.idle": "2023-01-21T04:21:59.676642Z",
     "shell.execute_reply": "2023-01-21T04:21:59.675915Z",
     "shell.execute_reply.started": "2023-01-21T04:21:59.663781Z"
    }
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba):\n",
    "    # Write predictions to a file\n",
    "    with open(\"../Submissions/geometric_GCNcov.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "433f567b-2a08-436c-9f79-71f195effcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T04:22:01.022241Z",
     "iopub.status.busy": "2023-01-21T04:22:01.021947Z",
     "iopub.status.idle": "2023-01-21T04:22:01.484124Z",
     "shell.execute_reply": "2023-01-21T04:22:01.483340Z",
     "shell.execute_reply.started": "2023-01-21T04:22:01.022219Z"
    }
   },
   "outputs": [],
   "source": [
    "submit(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b56a2aa-9d94-4880-9ada-91778ebb889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526ddf0-c6d6-4da4-b908-082208350f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
