{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d514801b-cb8f-49c6-85c5-84a49a687ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:46.319354Z",
     "iopub.status.busy": "2023-01-22T08:42:46.318935Z",
     "iopub.status.idle": "2023-01-22T08:42:58.098060Z",
     "shell.execute_reply": "2023-01-22T08:42:58.097307Z",
     "shell.execute_reply.started": "2023-01-22T08:42:46.319327Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# !pip install tensorflow\n",
    "# !pip install  spacy\n",
    "# !pip install tqdm\n",
    "# !pip install plotly\n",
    "!pip install jupyter-black\n",
    "!pip install imblearn\n",
    "!pip install joblib --upgrade\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab47875-d7b8-467e-9f9a-824abb3b9105",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92068b-ba2c-4f7d-b774-e77d9743c4f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3f4560-096a-4342-9371-ccb1bbaef8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:58.099943Z",
     "iopub.status.busy": "2023-01-22T08:42:58.099709Z",
     "iopub.status.idle": "2023-01-22T08:42:59.677705Z",
     "shell.execute_reply": "2023-01-22T08:42:59.676994Z",
     "shell.execute_reply.started": "2023-01-22T08:42:58.099920Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5fcdd3-4daf-4942-bdec-989e2c169e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.680116Z",
     "iopub.status.busy": "2023-01-22T08:42:59.678562Z",
     "iopub.status.idle": "2023-01-22T08:42:59.776454Z",
     "shell.execute_reply": "2023-01-22T08:42:59.775876Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.680095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a331634-a658-4862-acd5-cb498ef7064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.777395Z",
     "iopub.status.busy": "2023-01-22T08:42:59.777198Z",
     "iopub.status.idle": "2023-01-22T08:42:59.783585Z",
     "shell.execute_reply": "2023-01-22T08:42:59.782980Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.777376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44121573-5f12-45de-9286-3e7c4d79050d",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba141e71-43b6-4129-8477-8d5160f317dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.785703Z",
     "iopub.status.busy": "2023-01-22T08:42:59.785513Z",
     "iopub.status.idle": "2023-01-22T08:42:59.846278Z",
     "shell.execute_reply": "2023-01-22T08:42:59.845651Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.785685Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "# Read sequences\n",
    "sequences = list()\n",
    "with open(path + \"sequences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        sequences.append(line[:-1])\n",
    "\n",
    "# Split data into training and test sets\n",
    "sequences_train = list()\n",
    "sequences_test = list()\n",
    "proteins_test = list()\n",
    "train_target = list()\n",
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            sequences_test.append(sequences[i])\n",
    "        else:\n",
    "            sequences_train.append(sequences[i])\n",
    "            train_target.append(int(t[1][:-1]))\n",
    "\n",
    "sequences_train = np.array(sequences_train)\n",
    "train_target = np.array(train_target)\n",
    "sequences_test = np.array(sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d37beaf-7bc8-4804-b9e7-c69442ddd119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.847234Z",
     "iopub.status.busy": "2023-01-22T08:42:59.847030Z",
     "iopub.status.idle": "2023-01-22T08:42:59.859533Z",
     "shell.execute_reply": "2023-01-22T08:42:59.858863Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.847214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"seq\": sequences_train, \"target\": train_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e226940-ef41-4472-81cf-aa6197057635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.860638Z",
     "iopub.status.busy": "2023-01-22T08:42:59.860447Z",
     "iopub.status.idle": "2023-01-22T08:42:59.867108Z",
     "shell.execute_reply": "2023-01-22T08:42:59.866356Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.860620Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen = pd.DataFrame({\"seq\": sequences_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50ec40a-3d0e-4cb5-9272-18352a1dd755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:59.868078Z",
     "iopub.status.busy": "2023-01-22T08:42:59.867891Z",
     "iopub.status.idle": "2023-01-22T08:43:00.557341Z",
     "shell.execute_reply": "2023-01-22T08:43:00.556715Z",
     "shell.execute_reply.started": "2023-01-22T08:42:59.868060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAATsklEQVR4nO3df4wcZ33H8fe3MYEQU9tJ0DV1rDqUiCqNBXVOIRSKzrgKjoNwWgEKiogTUlmoCQ0lqHGLBIiqqmkVEKCKyiVRTBXhQIDaglBwnZwQfzglTkOcH9BcUgd8cuxCwoFJELj99o99ji6XO996d7x76+f9kk47+8wzM999dm4/N7Oze5GZSJLq9WuDLkCSNFgGgSRVziCQpMoZBJJUOYNAkiq3aNAFHMtZZ52VK1eu7Hr5n/70p5x++unNFXSCDVu9YM39Mmw1D1u9cHLVvHfv3h9k5ks7XlFmLtifCy+8MHtxzz339LR8vw1bvZnW3C/DVvOw1Zt5ctUM3JfH8VrrqSFJqpxBIEmVMwgkqXIGgSRVziCQpMrNGwQRcWtEHI6Ih9razoiIXRHxWLldVtojIj4RERMR8WBErG5bZmPp/1hEbDwxD0eSdLw6OSK4DVg3o20zsDszzwN2l/sAlwLnlZ9NwKegFRzAB4FXAxcBH5wOD0nSYM0bBJn5DeDpGc0bgG1lehtweVv7Z8qlrHuApRFxNvBGYFdmPp2ZzwC7eH64SJIGoNtPFo9k5sEy/RQwUqaXA99v63egtM3V/jwRsYnW0QQjIyOMj493WSIcOXKkp+X7bdjqBWvul2Gredjqhbpr7vkrJjIzI6Kx/26TmVuBrQCjo6M5NjbW9brGx8fpZfl+G7Z64eSteeXmrzSyrf1bLmtkPcM2zsNWL9Rdc7dXDR0qp3wot4dL+ySwoq3fOaVtrnZJ0oB1GwQ7gekrfzYCO9rarypXD10MTJVTSF8DLomIZeVN4ktKmyRpwOY9NRQRnwXGgLMi4gCtq3+2AJ+LiGuBJ4G3le53AeuBCeBZ4BqAzHw6Iv4a+Fbp9+HMnPkGtCRpAOYNgsx8+xyz1s7SN4Hr5ljPrcCtx1WdJOmE85PFklQ5g0CSKmcQSFLlDAJJqpxBIEmVMwgkqXIGgSRVrufvGlJnOvnumhtXHeXqefo19d01kjTNIwJJqpxBIEmVMwgkqXIGgSRVziCQpMoZBJJUOYNAkipnEEhS5QwCSaqcQSBJlTMIJKlyBoEkVc4gkKTKGQSSVDmDQJIqZxBIUuUMAkmqnEEgSZUzCCSpcgaBJFXOIJCkyhkEklQ5g0CSKmcQSFLlDAJJqlxPQRARfx4RD0fEQxHx2Yh4UUScGxH3RsRERNwREaeWvi8s9yfK/JWNPAJJUk+6DoKIWA78GTCamRcApwBXAB8BPpaZLweeAa4ti1wLPFPaP1b6SZIGrNdTQ4uA0yJiEfBi4CDwBuDOMn8bcHmZ3lDuU+avjYjocfuSpB5FZna/cMQNwN8AzwFfB24A9pS/+omIFcBXM/OCiHgIWJeZB8q8x4FXZ+YPZqxzE7AJYGRk5MLt27d3Xd+RI0dYvHhx18s3ad/k1Lx9Rk6DQ88du8+q5UsaqqgZC2mMO9VJzZ08X51o6vkatnEetnrh5Kp5zZo1ezNztNP1LOq2gIhYRuuv/HOBHwGfB9Z1u75pmbkV2AowOjqaY2NjXa9rfHycXpZv0tWbvzJvnxtXHeXmfcd+SvZfOdZQRc1YSGPcqU5q7uT56kRTz9ewjfOw1Qt119zLqaE/BP4rM/87M38BfBF4LbC0nCoCOAeYLNOTwAqAMn8J8MMeti9JakAvQfA94OKIeHE5178WeAS4B3hL6bMR2FGmd5b7lPl3Zy/npSRJjeg6CDLzXlpv+t4P7Cvr2grcBLw3IiaAM4FbyiK3AGeW9vcCm3uoW5LUkK7fIwDIzA8CH5zR/ARw0Sx9fwa8tZftSZKa5yeLJalyBoEkVc4gkKTKGQSSVDmDQJIqZxBIUuUMAkmqnEEgSZUzCCSpcgaBJFXOIJCkyhkEklQ5g0CSKmcQSFLlDAJJqpxBIEmVMwgkqXIGgSRVziCQpMoZBJJUOYNAkipnEEhS5QwCSaqcQSBJlTMIJKlyBoEkVc4gkKTKGQSSVDmDQJIqZxBIUuUWDboADbd9k1NcvfkrPa9n/5bLGqhGUjc8IpCkyvUUBBGxNCLujIjvRMSjEfGaiDgjInZFxGPldlnpGxHxiYiYiIgHI2J1Mw9BktSLXo8IPg78a2b+DvBK4FFgM7A7M88Ddpf7AJcC55WfTcCnety2JKkBXQdBRCwBXg/cApCZP8/MHwEbgG2l2zbg8jK9AfhMtuwBlkbE2d1uX5LUjMjM7haMeBWwFXiE1tHAXuAGYDIzl5Y+ATyTmUsj4svAlsz8Zpm3G7gpM++bsd5NtI4YGBkZuXD79u1d1Qdw5MgRFi9e3PXyTdo3OTVvn5HT4NBzx+6zavmShipqxuGnp+atuRP9fFyd7BedPF+daOpxLaR9uRPDVi+cXDWvWbNmb2aOdrqeXq4aWgSsBt6dmfdGxMf5/9NAAGRmRsRxJU1mbqUVMIyOjubY2FjXBY6Pj9PL8k3q5MqaG1cd5eZ9x35K9l851lBFzfjk7TvmrbkT/XxcnewXTVwJBc09roW0L3di2OqFumvu5T2CA8CBzLy33L+TVjAcmj7lU24Pl/mTwIq25c8pbZKkAeo6CDLzKeD7EfGK0rSW1mmincDG0rYR2FGmdwJXlauHLgamMvNgt9uXJDWj12P6dwO3R8SpwBPANbTC5XMRcS3wJPC20vcuYD0wATxb+kqSBqynIMjMB4DZ3pBYO0vfBK7rZXuSpOb5yWJJqpxBIEmVMwgkqXIGgSRVziCQpMr5/wgkDbWVDX0K/LZ1pzeynmHkEYEkVc4gkKTKGQSSVDmDQJIqZxBIUuUMAkmqnEEgSZUzCCSpcgaBJFXOIJCkyhkEklQ5g0CSKmcQSFLlDAJJqpxBIEmVMwgkqXIGgSRVziCQpMoZBJJUOYNAkipnEEhS5RYNuoATad/kFFdv/kpP69i/5bKGqpGkhckjAkmqnEEgSZUzCCSpcgaBJFXOIJCkyvUcBBFxSkT8R0R8udw/NyLujYiJiLgjIk4t7S8s9yfK/JW9bluS1LsmjghuAB5tu/8R4GOZ+XLgGeDa0n4t8Exp/1jpJ0kasJ6CICLOAS4DPl3uB/AG4M7SZRtweZneUO5T5q8t/SVJAxSZ2f3CEXcCfwu8BHgfcDWwp/zVT0SsAL6amRdExEPAusw8UOY9Drw6M38wY52bgE0AIyMjF27fvr3r+g4/PcWh57peHIBVy5f0toJi3+TUvH1GTmPeepuqpylNjDH093EdOXKExYsXH7NPJ89XJ5p6XJ3UvJD0s96mnqtzl5wyVGMMc4/zmjVr9mbmaKfr6fqTxRHxJuBwZu6NiLFu1zNTZm4FtgKMjo7m2Fj3q/7k7Tu4eV9vH57ef2X322/XySecb1x1dN56m6qnKU2MMfT3cY2PjzPfftXrJ9KnNfW4Oql5IelnvU09V7etO32oxhiaG+defoNfC7w5ItYDLwJ+Hfg4sDQiFmXmUeAcYLL0nwRWAAciYhGwBPhhD9uXJDWg6/cIMvMvM/OczFwJXAHcnZlXAvcAbyndNgI7yvTOcp8y/+7s5byUJKkRJ+JzBDcB742ICeBM4JbSfgtwZml/L7D5BGxbknScGvn20cwcB8bL9BPARbP0+Rnw1ia2J0lqjp8slqTKGQSSVDmDQJIqZxBIUuUMAkmqnEEgSZUzCCSpcgaBJFXOIJCkyhkEklQ5g0CSKmcQSFLlDAJJqpxBIEmVa+RrqCUtfCub+vebWy5rZD1aODwikKTKGQSSVDmDQJIqZxBIUuUMAkmqnEEgSZUzCCSpcgaBJFXOIJCkyhkEklQ5g0CSKmcQSFLlDAJJqpxBIEmVMwgkqXL+PwJJAvZNTnF1A/+zYRj/X4NHBJJUua6DICJWRMQ9EfFIRDwcETeU9jMiYldEPFZul5X2iIhPRMRERDwYEaubehCSpO71ckRwFLgxM88HLgaui4jzgc3A7sw8D9hd7gNcCpxXfjYBn+ph25KkhnQdBJl5MDPvL9M/AR4FlgMbgG2l2zbg8jK9AfhMtuwBlkbE2d1uX5LUjMjM3lcSsRL4BnAB8L3MXFraA3gmM5dGxJeBLZn5zTJvN3BTZt43Y12baB0xMDIycuH27du7ruvw01Mceq7rxQFYtXxJbyso9k1Ozdtn5DTmrbepeprSxBg3qZPxOXLkCIsXLz5mn06er6bq6UQnNc+nn4+piXo71dTj6uT3rxP9/B2da5zXrFmzNzNHO11Pz1cNRcRi4AvAezLzx63X/pbMzIg4rqTJzK3AVoDR0dEcGxvrurZP3r6Dm/f19hD3X9n99tt1cjXCjauOzltvU/U0pYkxblIn4zM+Ps58+1UTV490Wk8nOql5Pv18TE3U26mmHlcnv3+d6OfvaFPj3NNVQxHxAlohcHtmfrE0H5o+5VNuD5f2SWBF2+LnlDZJ0gD1ctVQALcAj2bmR9tm7QQ2lumNwI629qvK1UMXA1OZebDb7UuSmtHLcdBrgXcA+yLigdL2V8AW4HMRcS3wJPC2Mu8uYD0wATwLXNPDtiVJDek6CMqbvjHH7LWz9E/gum63J0k6MfxksSRVziCQpMoZBJJUOYNAkipnEEhS5QwCSaqcQSBJlTMIJKlyBoEkVc4gkKTKGQSSVDmDQJIqZxBIUuUWzr+WUl+tbOy/OjWyGkkDZBBIUoOa+iNr/5bLGllPJzw1JEmVMwgkqXIGgSRVziCQpMoZBJJUOa8a0kmlkys2blx1lKsburJDOhl4RCBJlTMIJKlynhoaMk19WEWSphkE0gnUVHDftu70RtazkPhHzcJhEMzDnVXSyc73CCSpch4RSENg3+TUgrnk1Ut0Tz4eEUhS5QwCSaqcQSBJlTMIJKlyBoEkVa7vQRAR6yLiuxExERGb+719SdKv6msQRMQpwD8AlwLnA2+PiPP7WYMk6Vf1+4jgImAiM5/IzJ8D24ENfa5BktQmMrN/G4t4C7AuM/+k3H8H8OrMvL6tzyZgU7n7CuC7PWzyLOAHPSzfb8NWL1hzvwxbzcNWL5xcNf9WZr6005UsuE8WZ+ZWYGsT64qI+zJztIl19cOw1QvW3C/DVvOw1Qt119zvU0OTwIq2++eUNknSgPQ7CL4FnBcR50bEqcAVwM4+1yBJatPXU0OZeTQirge+BpwC3JqZD5/ATTZyiqmPhq1esOZ+Gbaah61eqLjmvr5ZLElaePxksSRVziCQpMoNfRDM95UVEfHCiLijzL83IlYOoMz2elZExD0R8UhEPBwRN8zSZywipiLigfLzgUHUOqOm/RGxr9Rz3yzzIyI+Ucb5wYhYPYg62+p5Rdv4PRARP46I98zoM/BxjohbI+JwRDzU1nZGROyKiMfK7bI5lt1Y+jwWERsHWO/fR8R3yvP+pYhYOseyx9yH+lzzhyJisu25Xz/HsgP5Spw5ar6jrd79EfHAHMse/zhn5tD+0HrD+XHgZcCpwLeB82f0+VPgH8v0FcAdA675bGB1mX4J8J+z1DwGfHnQ4zujpv3AWceYvx74KhDAxcC9g655xn7yFK0P2SyocQZeD6wGHmpr+ztgc5neDHxkluXOAJ4ot8vK9LIB1XsJsKhMf2S2ejvZh/pc84eA93Ww3xzz9aWfNc+YfzPwgabGediPCDr5yooNwLYyfSewNiKijzX+isw8mJn3l+mfAI8CywdVT4M2AJ/Jlj3A0og4e9BFFWuBxzPzyUEXMlNmfgN4ekZz+z67Dbh8lkXfCOzKzKcz8xlgF7DuRNU5bbZ6M/PrmXm03N1D6/NBC8YcY9yJgX0lzrFqLq9fbwM+29T2hj0IlgPfb7t/gOe/qP6yT9lZp4Az+1LdPMppqt8D7p1l9msi4tsR8dWI+N3+VjarBL4eEXvL14DM1MlzMShXMPcvzUIbZ4CRzDxYpp8CRmbps1DH+520jgxnM98+1G/Xl9NZt85x+m2hjvEfAIcy87E55h/3OA97EAytiFgMfAF4T2b+eMbs+2mdxngl8EngX/pc3mxel5mraX1z7HUR8fpBF9SJ8sHFNwOfn2X2QhznX5GtY/2huMY7It4PHAVun6PLQtqHPgX8NvAq4CCtUy3D4u0c+2jguMd52IOgk6+s+GWfiFgELAF+2Jfq5hARL6AVArdn5hdnzs/MH2fmkTJ9F/CCiDirz2XOrGmy3B4GvkTrsLndQv36kEuB+zPz0MwZC3Gci0PTp9XK7eFZ+iyo8Y6Iq4E3AVeW8HqeDvahvsnMQ5n5P5n5v8A/zVHLghpj+OVr2B8Dd8zVp5txHvYg6OQrK3YC01dUvAW4e64dtR/K+b1bgEcz86Nz9PmN6fcxIuIiWs/TwMIrIk6PiJdMT9N6c/ChGd12AleVq4cuBqbaTm8M0px/PS20cW7Tvs9uBHbM0udrwCURsayc1riktPVdRKwD/gJ4c2Y+O0efTvahvpnx/tUfzVHLQvxKnD8EvpOZB2ab2fU49+Md8BP87vp6WlfePA68v7R9mNZOCfAiWqcFJoB/B1424HpfR+tQ/0HggfKzHngX8K7S53rgYVpXKewBfn/ANb+s1PLtUtf0OLfXHLT+6dDjwD5gdAHsG6fTemFf0ta2oMaZVkgdBH5B6xz0tbTew9oNPAb8G3BG6TsKfLpt2XeW/XoCuGaA9U7QOpc+vT9PX6X3m8Bdx9qHBljzP5f99EFaL+5nz6y53H/e68ugai7tt03vv219ex5nv2JCkio37KeGJEk9MggkqXIGgSRVziCQpMoZBJJUOYNAkipnEEhS5f4P32Ll6HWnu60AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.target.hist(bins=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd51e667-f8c5-4945-8da1-fb1460e584ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:00.558422Z",
     "iopub.status.busy": "2023-01-22T08:43:00.558135Z",
     "iopub.status.idle": "2023-01-22T08:43:00.624267Z",
     "shell.execute_reply": "2023-01-22T08:43:00.623681Z",
     "shell.execute_reply.started": "2023-01-22T08:43:00.558403Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab595103cf3b475db23a1c1ad15947d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb905fff3f94e2d9f9a73036a87e1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258.14279869067104\n",
      "mean 258.14279869067104 and std is 162.24346887570542\n"
     ]
    }
   ],
   "source": [
    "mean_carr = np.mean(data.seq.progress_apply(len))\n",
    "std_carr = np.std(data.seq.progress_apply(len))\n",
    "print(mean_carr)\n",
    "print(\"mean\", mean_carr, \"and std is\", std_carr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f8a40-d81d-4c7a-ab87-6cf914da9fc4",
   "metadata": {},
   "source": [
    "We notice that the target isn't balanced, so we will take that into consideration by :\n",
    "- adding sample weight in logistic regression and the other models that supports weight to impact directly the loss function\n",
    "- we can make an oversampling using duplication which is poor or using smote (that add some guassian noise )\n",
    "- we can make an undersampling by reducing the number of majority class samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1968a-5a81-4861-a099-c1346ec96ddc",
   "metadata": {},
   "source": [
    "### Important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a916f1a-317a-402a-9ec6-db0923a97dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:00.625197Z",
     "iopub.status.busy": "2023-01-22T08:43:00.624993Z",
     "iopub.status.idle": "2023-01-22T08:43:00.632581Z",
     "shell.execute_reply": "2023-01-22T08:43:00.631874Z",
     "shell.execute_reply.started": "2023-01-22T08:43:00.625177Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x - np.max(x))\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "\n",
    "softmax_vect = np.vectorize(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8af066c-582f-4792-abaa-5f32e32f2ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:00.633458Z",
     "iopub.status.busy": "2023-01-22T08:43:00.633279Z",
     "iopub.status.idle": "2023-01-22T08:43:00.645896Z",
     "shell.execute_reply": "2023-01-22T08:43:00.645310Z",
     "shell.execute_reply.started": "2023-01-22T08:43:00.633440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted multi-class log loss\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def weighted_mc_log_loss(y_true, y_pred, y_pred_proba):\n",
    "    loss = log_loss(y_true, y_pred_proba, labels=np.unique(y_true))\n",
    "    accuracy = round((y_true == y_pred).sum() / len(y_true) * 100, 2)\n",
    "    return print(f\"{loss = } and accuracy {accuracy = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00dc7a6f-c7d5-4cbb-b0a7-539e42eeeb2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:00.646837Z",
     "iopub.status.busy": "2023-01-22T08:43:00.646634Z",
     "iopub.status.idle": "2023-01-22T08:43:00.659229Z",
     "shell.execute_reply": "2023-01-22T08:43:00.658702Z",
     "shell.execute_reply.started": "2023-01-22T08:43:00.646819Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba, name=\"\"):\n",
    "    # Write predictions to a file\n",
    "    with open(\"../Submissions/\" + name + \"Graph_gcn.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d628810-a306-488c-b82b-cf58036532fa",
   "metadata": {},
   "source": [
    "# using structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be017f7-0fea-45fd-ae55-1f00d2c60aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:00.660270Z",
     "iopub.status.busy": "2023-01-22T08:43:00.660082Z",
     "iopub.status.idle": "2023-01-22T08:43:01.303311Z",
     "shell.execute_reply": "2023-01-22T08:43:01.302617Z",
     "shell.execute_reply.started": "2023-01-22T08:43:00.660252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cc2aae1-32bf-4772-8bb2-b001267ecc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:01.307474Z",
     "iopub.status.busy": "2023-01-22T08:43:01.306561Z",
     "iopub.status.idle": "2023-01-22T08:43:01.340788Z",
     "shell.execute_reply": "2023-01-22T08:43:01.340181Z",
     "shell.execute_reply.started": "2023-01-22T08:43:01.307453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function that loads graphs\n",
    "    \"\"\"\n",
    "    graph_indicator = np.loadtxt(path + \"graph_indicator.txt\", dtype=np.int64)\n",
    "    _, graph_size = np.unique(graph_indicator, return_counts=True)\n",
    "\n",
    "    edges = np.loadtxt(path + \"edgelist.txt\", dtype=np.int64, delimiter=\",\")\n",
    "    edges_inv = np.vstack((edges[:, 1], edges[:, 0]))\n",
    "    edges = np.vstack((edges, edges_inv.T))\n",
    "    s = edges[:, 0] * graph_indicator.size + edges[:, 1]\n",
    "    idx_sort = np.argsort(s)\n",
    "    edges = edges[idx_sort, :]\n",
    "    edges, idx_unique = np.unique(edges, axis=0, return_index=True)\n",
    "    A = sp.csr_matrix(\n",
    "        (np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "        shape=(graph_indicator.size, graph_indicator.size),\n",
    "    )\n",
    "\n",
    "    x = np.loadtxt(path + \"node_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.loadtxt(path + \"edge_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.vstack((edge_attr, edge_attr))\n",
    "    edge_attr = edge_attr[idx_sort, :]\n",
    "    edge_attr = edge_attr[idx_unique, :]\n",
    "\n",
    "    adj = []\n",
    "    features = []\n",
    "    edge_features = []\n",
    "    idx_n = 0\n",
    "    idx_m = 0\n",
    "    for i in range(graph_size.size):\n",
    "        adj.append(A[idx_n : idx_n + graph_size[i], idx_n : idx_n + graph_size[i]])\n",
    "        edge_features.append(edge_attr[idx_m : idx_m + adj[i].nnz, :])\n",
    "        features.append(x[idx_n : idx_n + graph_size[i], :])\n",
    "        idx_n += graph_size[i]\n",
    "        idx_m += adj[i].nnz\n",
    "\n",
    "    return adj, features, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a06e3c3-1719-45bc-b17d-57424bbe290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:01.343393Z",
     "iopub.status.busy": "2023-01-22T08:43:01.343226Z",
     "iopub.status.idle": "2023-01-22T08:43:01.359803Z",
     "shell.execute_reply": "2023-01-22T08:43:01.359263Z",
     "shell.execute_reply.started": "2023-01-22T08:43:01.343376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_adjacency(A):\n",
    "    \"\"\"\n",
    "    Function that normalizes an adjacency matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    A += sp.identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D = sp.diags(inv_degs)\n",
    "    A_normalized = D.dot(A)\n",
    "\n",
    "    return A_normalized\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"\n",
    "    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n",
    "    \"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f55ecfc7-9ea9-4a15-83e5-18128cabacee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:01.362402Z",
     "iopub.status.busy": "2023-01-22T08:43:01.362227Z",
     "iopub.status.idle": "2023-01-22T08:43:26.367444Z",
     "shell.execute_reply": "2023-01-22T08:43:26.366734Z",
     "shell.execute_reply.started": "2023-01-22T08:43:01.362384Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load graphs\n",
    "adj, features, edge_features = load_data()\n",
    "\n",
    "# Normalize adjacency matrices\n",
    "# adj = [normalize_adjacency(A) for A in adj]\n",
    "\n",
    "# Split data into training and test sets\n",
    "adj_train = list()\n",
    "features_train = list()\n",
    "edge_features_train = list()\n",
    "y_train = list()\n",
    "adj_test = list()\n",
    "features_test = list()\n",
    "edge_features_test = list()\n",
    "proteins_test = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f03e358d-2664-4d0f-9450-71e561e6bf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:26.370170Z",
     "iopub.status.busy": "2023-01-22T08:43:26.369998Z",
     "iopub.status.idle": "2023-01-22T08:43:26.388318Z",
     "shell.execute_reply": "2023-01-22T08:43:26.387585Z",
     "shell.execute_reply.started": "2023-01-22T08:43:26.370151Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            adj_test.append(adj[i])\n",
    "            features_test.append(features[i])\n",
    "            edge_features_test.append(edge_features[i])\n",
    "        else:\n",
    "            adj_train.append(adj[i])\n",
    "            features_train.append(features[i])\n",
    "            edge_features_train.append(edge_features[i])\n",
    "            y_train.append(int(t[1][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b944a73a-0dbb-4772-bcf3-ceb810adb974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:43:26.390868Z",
     "iopub.status.busy": "2023-01-22T08:43:26.390701Z",
     "iopub.status.idle": "2023-01-22T08:43:26.393954Z",
     "shell.execute_reply": "2023-01-22T08:43:26.393315Z",
     "shell.execute_reply.started": "2023-01-22T08:43:26.390850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adj_train = adj_train[:50].copy()\n",
    "# features_train = features_train[:50].copy()\n",
    "# edge_features_train = edge_features_train[:50].copy()\n",
    "# y_train = y_train[:50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b379b1a-0af4-475a-86fa-a226514fc21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:46:58.348338Z",
     "iopub.status.busy": "2023-01-22T08:46:58.347636Z",
     "iopub.status.idle": "2023-01-22T08:49:19.866286Z",
     "shell.execute_reply": "2023-01-22T08:49:19.865425Z",
     "shell.execute_reply.started": "2023-01-22T08:46:58.348314Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib as joblib\n",
    "\n",
    "features_train = joblib.load(\"new_features_3B_params.sav\")\n",
    "# features_test = joblib.load(\"new_features_test_3B_params.sav\").tolist()\n",
    "n_input = features_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865db7f2-e812-434c-9a9a-b09cd4768814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:53:15.346396Z",
     "iopub.status.busy": "2023-01-22T08:53:15.346077Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "features_train = [Data(x=torch.tensor(features_train[i]).float(), edge_index= torch.tensor(adj_train[i].todense()).nonzero().t().contiguous()) for i in range(len(features_train)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7460f107-922b-4852-be12-b9b6c13decf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:49:31.256514Z",
     "iopub.status.busy": "2023-01-22T08:49:31.256199Z",
     "iopub.status.idle": "2023-01-22T08:49:31.356268Z",
     "shell.execute_reply": "2023-01-22T08:49:31.355578Z",
     "shell.execute_reply.started": "2023-01-22T08:49:31.256488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# del my_array\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dac71149-8aa1-4fab-b715-bdd27be9ee9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:36:38.339477Z",
     "iopub.status.busy": "2023-01-22T08:36:38.338926Z",
     "iopub.status.idle": "2023-01-22T08:36:38.345017Z",
     "shell.execute_reply": "2023-01-22T08:36:38.344257Z",
     "shell.execute_reply.started": "2023-01-22T08:36:38.339454Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 2646)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d860c8-ba16-4e82-8170-be6d09188d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:42:27.406752Z",
     "iopub.status.busy": "2023-01-22T08:42:27.406204Z",
     "iopub.status.idle": "2023-01-22T08:42:27.411339Z",
     "shell.execute_reply": "2023-01-22T08:42:27.410728Z",
     "shell.execute_reply.started": "2023-01-22T08:42:27.406724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5], [4]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a= np.array([[5],[4]]).tolist()\n",
    "b=[5]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b34880-1507-4f1e-9695-80e14652d2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T08:36:54.169586Z",
     "iopub.status.busy": "2023-01-22T08:36:54.168919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def get_Data(adj_train, features_train, edge_features_train, y_train):\n",
    "    data = []\n",
    "    for i in range(len(features_train)):\n",
    "        adj_t = torch.tensor(adj_train[i].todense())\n",
    "        edge_index = adj_t.nonzero().t().contiguous()\n",
    "        x = torch.tensor(features_train[i]).float()\n",
    "        edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y_train[i]))\n",
    "    return data\n",
    "\n",
    "\n",
    "data_obj = get_Data(adj_train, features_train, edge_features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794e1c52-cc8a-476b-a838-216df7e94166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:54.739289Z",
     "iopub.status.busy": "2023-01-21T21:43:54.738732Z",
     "iopub.status.idle": "2023-01-21T21:43:55.716768Z",
     "shell.execute_reply": "2023-01-21T21:43:55.716236Z",
     "shell.execute_reply.started": "2023-01-21T21:43:54.739260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Data_pred(adj_train, features_train, edge_features_train):\n",
    "    data = []\n",
    "    for i in range(len(features_train)):\n",
    "        adj_t = torch.tensor(adj_train[i].todense())\n",
    "        edge_index = adj_t.nonzero().t().contiguous()\n",
    "        x = torch.tensor(features_train[i]).float()\n",
    "        edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "        data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr))\n",
    "    return data\n",
    "\n",
    "\n",
    "features_train = get_Data_pred(adj_test, features_test, edge_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae53b548-e3e9-4d1a-b8c0-934ac088886a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:55.720222Z",
     "iopub.status.busy": "2023-01-21T21:43:55.719654Z",
     "iopub.status.idle": "2023-01-21T21:43:55.727640Z",
     "shell.execute_reply": "2023-01-21T21:43:55.727092Z",
     "shell.execute_reply.started": "2023-01-21T21:43:55.720200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 4399\n",
      "Number of test graphs: 489\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_obj[: int(len(data_obj) * 9 / 10)]\n",
    "test_dataset = data_obj[int(len(data_obj) * 9 / 10) :]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba173eb-176a-4f18-9a29-e33c980ac76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:55.728380Z",
     "iopub.status.busy": "2023-01-21T21:43:55.728223Z",
     "iopub.status.idle": "2023-01-21T21:43:55.735461Z",
     "shell.execute_reply": "2023-01-21T21:43:55.734991Z",
     "shell.execute_reply.started": "2023-01-21T21:43:55.728365Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "pred_loader = DataLoader(data_obj_pred, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c972da03-e02c-4124-bd1f-2e027e1f31b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:55.736215Z",
     "iopub.status.busy": "2023-01-21T21:43:55.736053Z",
     "iopub.status.idle": "2023-01-21T21:43:55.739374Z",
     "shell.execute_reply": "2023-01-21T21:43:55.738883Z",
     "shell.execute_reply.started": "2023-01-21T21:43:55.736193Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neigh_loader = []\n",
    "# for i in range(len(train_dataset)):\n",
    "#     loader = NeighborSampler(\n",
    "#         train_dataset[i].edge_index, sizes=[30], batch_size=32, shuffle=True\n",
    "#     )\n",
    "#     sampled_data = next(iter(loader))\n",
    "#     neigh_loader.append(sampled_data)\n",
    "# train_loader = DataLoader(neigh_loader, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19dbe0be-36d4-47c3-9295-6c152c445943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:55.740191Z",
     "iopub.status.busy": "2023-01-21T21:43:55.740012Z",
     "iopub.status.idle": "2023-01-21T21:43:56.838527Z",
     "shell.execute_reply": "2023-01-21T21:43:56.837966Z",
     "shell.execute_reply.started": "2023-01-21T21:43:55.740175Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[2392, 726], edge_index=[2, 45692], edge_attr=[45692, 5], y=[8], batch=[2392], ptr=[9])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[2773, 726], edge_index=[2, 52817], edge_attr=[52817, 5], y=[8], batch=[2773], ptr=[9])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[1414, 726], edge_index=[2, 24402], edge_attr=[24402, 5], y=[8], batch=[1414], ptr=[9])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[2303, 726], edge_index=[2, 41717], edge_attr=[41717, 5], y=[8], batch=[2303], ptr=[9])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 8\n",
      "DataBatch(x=[2698, 726], edge_index=[2, 48496], edge_attr=[48496, 5], y=[8], batch=[2698], ptr=[9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    if step < 5:\n",
    "        print(f\"Step {step + 1}:\")\n",
    "        print(\"=======\")\n",
    "        print(f\"Number of graphs in the current batch: {data.num_graphs}\")\n",
    "        print(data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9d7e6-66a9-4808-aef3-35f8d6b2863f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08515985-954f-4847-9d62-9713fe203c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:56.839799Z",
     "iopub.status.busy": "2023-01-21T21:43:56.839313Z",
     "iopub.status.idle": "2023-01-21T21:43:56.845041Z",
     "shell.execute_reply": "2023-01-21T21:43:56.844579Z",
     "shell.execute_reply.started": "2023-01-21T21:43:56.839770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03dd6a35-7b3e-4a5a-a935-e8862ca4ef08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:04:54.649934Z",
     "iopub.status.busy": "2023-01-21T22:04:54.649672Z",
     "iopub.status.idle": "2023-01-21T22:04:54.881610Z",
     "shell.execute_reply": "2023-01-21T22:04:54.881071Z",
     "shell.execute_reply.started": "2023-01-21T22:04:54.649916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (layer1): GCNConv(726, 64)\n",
      "  (layer2): GCNConv(64, 32)\n",
      "  (decoder): Linear(in_features=32, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "num_node_features = features_train[0].shape[1]\n",
    "num_classes = 18\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"GCN\",\n",
    "        hidden_channels=[64, 64, 32],\n",
    "        num_heads=[1, 1, 1],\n",
    "        dropout=0.02,\n",
    "        n_classes=num_classes,\n",
    "        input_dim=num_node_features,\n",
    "    ):\n",
    "        super(GNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_channels[2]\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == \"GCN\":\n",
    "            self.layer1 = GCNConv(\n",
    "                in_channels=input_dim, out_channels=hidden_channels[1]\n",
    "            )\n",
    "            self.layer2 = GCNConv(\n",
    "                in_channels=hidden_channels[1], out_channels=hidden_channels[2]\n",
    "            )\n",
    "            # self.layer3 = GCNConv(\n",
    "            #     in_channels=hidden_channels[1], out_channels=hidden_channels[2]\n",
    "            # )\n",
    "\n",
    "        elif model_name == \"GAT\":\n",
    "            self.layer1 = GATConv(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=hidden_channels[0],\n",
    "                heads=num_heads[0],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer2 = GATConv(\n",
    "                hidden_channels[0] * num_heads[0],\n",
    "                hidden_channels[1],\n",
    "                heads=num_heads[1],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer3 = GATConv(\n",
    "                hidden_channels[1] * num_heads[1],\n",
    "                hidden_channels[2],\n",
    "                heads=1,\n",
    "                edge_dim=5,\n",
    "                concat=False,\n",
    "            )\n",
    "\n",
    "        elif model_name == \"GraphSAGE\":\n",
    "            self.layer1 = SAGEConv(input_dim, hidden_channels[0], aggr=\"lstm\")\n",
    "            self.layer2 = SAGEConv(hidden_channels[0], hidden_channels[1], aggr=\"lstm\")\n",
    "            self.layer3 = SAGEConv(hidden_channels[1], hidden_channels[2], aggr=\"lstm\")\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_channels[2], n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        if self.model_name == \"GAT\":\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer1(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer2(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer3(x, edge_index, edge_attr)\n",
    "        else:\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            x = self.layer2(x, edge_index)\n",
    "\n",
    "            # x = F.relu(x)\n",
    "            # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            # x = self.layer3(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        # x = global_add_pool(x, batch)\n",
    "        # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "model = GNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb5c359-513f-49e7-9938-9445467ac294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:35.612185Z",
     "iopub.status.busy": "2023-01-21T21:42:35.611374Z",
     "iopub.status.idle": "2023-01-21T21:42:35.644025Z",
     "shell.execute_reply": "2023-01-21T21:42:35.643540Z",
     "shell.execute_reply.started": "2023-01-21T21:42:35.612166Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function that loads graphs\n",
    "    \"\"\"\n",
    "    graph_indicator = np.loadtxt(path + \"graph_indicator.txt\", dtype=np.int64)\n",
    "    _, graph_size = np.unique(graph_indicator, return_counts=True)\n",
    "\n",
    "    edges = np.loadtxt(path + \"edgelist.txt\", dtype=np.int64, delimiter=\",\")\n",
    "    edges_inv = np.vstack((edges[:, 1], edges[:, 0]))\n",
    "    edges = np.vstack((edges, edges_inv.T))\n",
    "    s = edges[:, 0] * graph_indicator.size + edges[:, 1]\n",
    "    idx_sort = np.argsort(s)\n",
    "    edges = edges[idx_sort, :]\n",
    "    edges, idx_unique = np.unique(edges, axis=0, return_index=True)\n",
    "    A = sp.csr_matrix(\n",
    "        (np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "        shape=(graph_indicator.size, graph_indicator.size),\n",
    "    )\n",
    "\n",
    "    x = np.loadtxt(path + \"node_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.loadtxt(path + \"edge_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.vstack((edge_attr, edge_attr))\n",
    "    edge_attr = edge_attr[idx_sort, :]\n",
    "    edge_attr = edge_attr[idx_unique, :]\n",
    "\n",
    "    adj = []\n",
    "    features = []\n",
    "    edge_features = []\n",
    "    idx_n = 0\n",
    "    idx_m = 0\n",
    "    for i in range(graph_size.size):\n",
    "        adj.append(A[idx_n : idx_n + graph_size[i], idx_n : idx_n + graph_size[i]])\n",
    "        edge_features.append(edge_attr[idx_m : idx_m + adj[i].nnz, :])\n",
    "        features.append(x[idx_n : idx_n + graph_size[i], :])\n",
    "        idx_n += graph_size[i]\n",
    "        idx_m += adj[i].nnz\n",
    "\n",
    "    return adj, features, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812f687f-53a0-4c23-9500-553a3928fc14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:35.645403Z",
     "iopub.status.busy": "2023-01-21T21:42:35.644684Z",
     "iopub.status.idle": "2023-01-21T21:42:35.660486Z",
     "shell.execute_reply": "2023-01-21T21:42:35.660021Z",
     "shell.execute_reply.started": "2023-01-21T21:42:35.645383Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_adjacency(A):\n",
    "    \"\"\"\n",
    "    Function that normalizes an adjacency matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    A += sp.identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D = sp.diags(inv_degs)\n",
    "    A_normalized = D.dot(A)\n",
    "\n",
    "    return A_normalized\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"\n",
    "    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n",
    "    \"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea70be7-5e85-4305-910a-e5584bbbb980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:35.661743Z",
     "iopub.status.busy": "2023-01-21T21:42:35.661189Z",
     "iopub.status.idle": "2023-01-21T21:42:59.217837Z",
     "shell.execute_reply": "2023-01-21T21:42:59.216996Z",
     "shell.execute_reply.started": "2023-01-21T21:42:35.661723Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load graphs\n",
    "adj, features, edge_features = load_data()\n",
    "\n",
    "# Normalize adjacency matrices\n",
    "# adj = [normalize_adjacency(A) for A in adj]\n",
    "\n",
    "# Split data into training and test sets\n",
    "adj_train = list()\n",
    "features_train = list()\n",
    "edge_features_train = list()\n",
    "y_train = list()\n",
    "adj_test = list()\n",
    "features_test = list()\n",
    "edge_features_test = list()\n",
    "proteins_test = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63043c3a-4cb7-4812-a586-70531c3dceb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:59.220319Z",
     "iopub.status.busy": "2023-01-21T21:42:59.220038Z",
     "iopub.status.idle": "2023-01-21T21:42:59.238882Z",
     "shell.execute_reply": "2023-01-21T21:42:59.238357Z",
     "shell.execute_reply.started": "2023-01-21T21:42:59.220300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            adj_test.append(adj[i])\n",
    "            features_test.append(features[i])\n",
    "            edge_features_test.append(edge_features[i])\n",
    "        else:\n",
    "            adj_train.append(adj[i])\n",
    "            features_train.append(features[i])\n",
    "            edge_features_train.append(edge_features[i])\n",
    "            y_train.append(int(t[1][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2387596e-8143-47a9-be53-03ff7b69c67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:59.240504Z",
     "iopub.status.busy": "2023-01-21T21:42:59.239866Z",
     "iopub.status.idle": "2023-01-21T21:42:59.243648Z",
     "shell.execute_reply": "2023-01-21T21:42:59.243136Z",
     "shell.execute_reply.started": "2023-01-21T21:42:59.240483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adj_train = adj_train[:50].copy()\n",
    "# features_train = features_train[:50].copy()\n",
    "# edge_features_train = edge_features_train[:50].copy()\n",
    "# y_train = y_train[:50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "059b2f83-b696-4498-afd0-ba0fc7d9e710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T21:42:59.244476Z",
     "iopub.status.busy": "2023-01-21T21:42:59.244313Z",
     "iopub.status.idle": "2023-01-21T21:43:50.099480Z",
     "shell.execute_reply": "2023-01-21T21:43:50.098866Z",
     "shell.execute_reply.started": "2023-01-21T21:42:59.244462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib as joblib\n",
    "\n",
    "features_train = joblib.load(\"new_features_150m_params.sav\")\n",
    "features_test = joblib.load(\"new_features_test_150m_params.sav\")\n",
    "n_input = features_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc335430-b5a7-4fc8-8070-7ca80b9bb273",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-01-21T21:43:50.100570Z",
     "iopub.status.busy": "2023-01-21T21:43:50.100388Z",
     "iopub.status.idle": "2023-01-21T21:43:50.105394Z",
     "shell.execute_reply": "2023-01-21T21:43:50.104853Z",
     "shell.execute_reply.started": "2023-01-21T21:43:50.100554Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 726)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6212a50-6ae4-4edf-82b4-caa7770e4b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:30:05.878513Z",
     "iopub.status.busy": "2023-01-21T22:30:05.877751Z",
     "iopub.status.idle": "2023-01-21T22:34:51.167783Z",
     "shell.execute_reply": "2023-01-21T22:34:51.165842Z",
     "shell.execute_reply.started": "2023-01-21T22:30:05.878491Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 loss_train: 0.6777 acc_train: 79.3589 loss_val: 1.2470\n",
      "(67.07566462167689, tensor(1.2470, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation Loss Decreased(inf--->1.246997) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 001\n",
      "Epoch: 002 loss_train: 0.6702 acc_train: 80.1546 loss_val: 1.2231\n",
      "(70.14314928425358, tensor(1.2231, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation Loss Decreased(1.246997--->1.223093) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 002\n",
      "Epoch: 003 loss_train: 0.6717 acc_train: 79.7454 loss_val: 1.1853\n",
      "(69.12065439672801, tensor(1.1853, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation Loss Decreased(1.223093--->1.185338) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 003\n",
      "Epoch: 004 loss_train: 0.6736 acc_train: 80.0409 loss_val: 1.3151\n",
      "(67.89366053169734, tensor(1.3151, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 004\n",
      "Epoch: 005 loss_train: 0.6654 acc_train: 79.5863 loss_val: 1.2144\n",
      "(68.9161554192229, tensor(1.2144, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 005\n",
      "Epoch: 006 loss_train: 0.6683 acc_train: 79.1998 loss_val: 1.2190\n",
      "(68.30265848670757, tensor(1.2190, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 006\n",
      "Epoch: 007 loss_train: 0.6635 acc_train: 80.2000 loss_val: 1.2021\n",
      "(68.9161554192229, tensor(1.2021, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 007\n",
      "Epoch: 008 loss_train: 0.6570 acc_train: 80.4046 loss_val: 1.2130\n",
      "(69.52965235173824, tensor(1.2130, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 008\n",
      "Epoch: 009 loss_train: 0.6611 acc_train: 80.1091 loss_val: 1.3122\n",
      "(66.05316973415133, tensor(1.3122, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 009\n",
      "Epoch: 010 loss_train: 0.6653 acc_train: 80.0409 loss_val: 1.2126\n",
      "(70.14314928425358, tensor(1.2126, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 010\n",
      "Epoch: 011 loss_train: 0.6515 acc_train: 80.3592 loss_val: 1.2976\n",
      "(67.89366053169734, tensor(1.2976, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 011\n",
      "Epoch: 012 loss_train: 0.6534 acc_train: 80.5410 loss_val: 1.2749\n",
      "(67.68916155419224, tensor(1.2749, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 012\n",
      "Epoch: 013 loss_train: 0.6520 acc_train: 79.9500 loss_val: 1.2553\n",
      "(66.25766871165644, tensor(1.2553, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 013\n",
      "Epoch: 014 loss_train: 0.6448 acc_train: 80.9957 loss_val: 1.2142\n",
      "(70.14314928425358, tensor(1.2142, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 014\n",
      "Epoch: 015 loss_train: 0.6444 acc_train: 80.3819 loss_val: 1.2105\n",
      "(69.32515337423312, tensor(1.2105, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 015\n",
      "Epoch: 016 loss_train: 0.6505 acc_train: 79.8818 loss_val: 1.2276\n",
      "(69.32515337423312, tensor(1.2276, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 016\n",
      "Epoch: 017 loss_train: 0.6483 acc_train: 80.2682 loss_val: 1.3119\n",
      "(66.66666666666666, tensor(1.3119, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 017\n",
      "Epoch: 018 loss_train: 0.6424 acc_train: 80.7002 loss_val: 1.2157\n",
      "(69.93865030674846, tensor(1.2157, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 018\n",
      "Epoch: 019 loss_train: 0.6429 acc_train: 80.5865 loss_val: 1.2086\n",
      "(69.93865030674846, tensor(1.2086, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 019\n",
      "Epoch: 020 loss_train: 0.6338 acc_train: 80.9502 loss_val: 1.2779\n",
      "(67.07566462167689, tensor(1.2779, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 020\n",
      "Epoch: 021 loss_train: 0.6337 acc_train: 80.8593 loss_val: 1.1953\n",
      "(69.93865030674846, tensor(1.1953, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 021\n",
      "Epoch: 022 loss_train: 0.6347 acc_train: 80.5410 loss_val: 1.2344\n",
      "(69.32515337423312, tensor(1.2344, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 022\n",
      "Epoch: 023 loss_train: 0.6295 acc_train: 80.8593 loss_val: 1.2688\n",
      "(69.52965235173824, tensor(1.2688, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 023\n",
      "Epoch: 024 loss_train: 0.6338 acc_train: 80.8820 loss_val: 1.2093\n",
      "(68.9161554192229, tensor(1.2093, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 024\n",
      "Epoch: 025 loss_train: 0.6233 acc_train: 81.2457 loss_val: 1.2371\n",
      "(67.68916155419224, tensor(1.2371, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 025\n",
      "Epoch: 026 loss_train: 0.6339 acc_train: 80.6547 loss_val: 1.2033\n",
      "(69.32515337423312, tensor(1.2033, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 026\n",
      "Epoch: 027 loss_train: 0.6317 acc_train: 81.2003 loss_val: 1.1768\n",
      "(70.5521472392638, tensor(1.1768, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation Loss Decreased(1.185338--->1.176846) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 027\n",
      "Epoch: 028 loss_train: 0.6249 acc_train: 80.7684 loss_val: 1.2091\n",
      "(68.71165644171779, tensor(1.2091, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 028\n",
      "Epoch: 029 loss_train: 0.6246 acc_train: 81.4958 loss_val: 1.2709\n",
      "(66.87116564417178, tensor(1.2709, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 029\n",
      "Epoch: 030 loss_train: 0.6184 acc_train: 81.2230 loss_val: 1.2034\n",
      "(68.50715746421268, tensor(1.2034, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 030\n",
      "Epoch: 031 loss_train: 0.6163 acc_train: 81.3821 loss_val: 1.2403\n",
      "(67.89366053169734, tensor(1.2403, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 031\n",
      "Epoch: 032 loss_train: 0.6243 acc_train: 80.8820 loss_val: 1.2623\n",
      "(68.50715746421268, tensor(1.2623, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 032\n",
      "Epoch: 033 loss_train: 0.6136 acc_train: 81.7459 loss_val: 1.2299\n",
      "(69.12065439672801, tensor(1.2299, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 033\n",
      "Epoch: 034 loss_train: 0.6190 acc_train: 81.0411 loss_val: 1.2896\n",
      "(66.87116564417178, tensor(1.2896, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 034\n",
      "Epoch: 035 loss_train: 0.6039 acc_train: 81.9732 loss_val: 1.2410\n",
      "(66.87116564417178, tensor(1.2410, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 035\n",
      "Epoch: 036 loss_train: 0.6153 acc_train: 81.3594 loss_val: 1.2661\n",
      "(69.12065439672801, tensor(1.2661, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 036\n",
      "Epoch: 037 loss_train: 0.6133 acc_train: 81.1093 loss_val: 1.2179\n",
      "(68.71165644171779, tensor(1.2179, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 037\n",
      "Epoch: 038 loss_train: 0.6019 acc_train: 82.4960 loss_val: 1.2158\n",
      "(68.9161554192229, tensor(1.2158, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 038\n",
      "Epoch: 039 loss_train: 0.6093 acc_train: 81.3594 loss_val: 1.2558\n",
      "(68.71165644171779, tensor(1.2558, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 039\n",
      "Epoch: 040 loss_train: 0.5997 acc_train: 82.0186 loss_val: 1.2277\n",
      "(69.73415132924336, tensor(1.2277, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 040\n",
      "Epoch: 041 loss_train: 0.5981 acc_train: 81.9277 loss_val: 1.2419\n",
      "(69.93865030674846, tensor(1.2419, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 041\n",
      "Epoch: 042 loss_train: 0.5936 acc_train: 81.6777 loss_val: 1.3060\n",
      "(68.50715746421268, tensor(1.3060, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 042\n",
      "Epoch: 043 loss_train: 0.5978 acc_train: 81.4731 loss_val: 1.3062\n",
      "(68.71165644171779, tensor(1.3062, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 043\n",
      "Epoch: 044 loss_train: 0.5934 acc_train: 81.5867 loss_val: 1.2636\n",
      "(68.9161554192229, tensor(1.2636, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 044\n",
      "Epoch: 045 loss_train: 0.5955 acc_train: 81.2912 loss_val: 1.2794\n",
      "(66.87116564417178, tensor(1.2794, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 045\n",
      "Epoch: 046 loss_train: 0.5869 acc_train: 81.8822 loss_val: 1.3093\n",
      "(66.87116564417178, tensor(1.3093, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 046\n",
      "Epoch: 047 loss_train: 0.5931 acc_train: 82.1096 loss_val: 1.3016\n",
      "(66.66666666666666, tensor(1.3016, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 047\n",
      "Epoch: 048 loss_train: 0.5912 acc_train: 82.0641 loss_val: 1.2640\n",
      "(68.09815950920245, tensor(1.2640, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 048\n",
      "Epoch: 049 loss_train: 0.5845 acc_train: 81.7459 loss_val: 1.2712\n",
      "(69.32515337423312, tensor(1.2712, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 049\n",
      "Epoch: 050 loss_train: 0.5864 acc_train: 82.1550 loss_val: 1.2557\n",
      "(69.12065439672801, tensor(1.2557, device='cuda:0', grad_fn=<DivBackward0>))\n",
      "Validation loss increased :(\n",
      "Epoch: 050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m min_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m401\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# train_acc, train_loss = test(train_loader)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)  \u001b[38;5;66;03m# Compute the loss.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# test part\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py:264\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = GCN(hidden_channels=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4) #weight_decay=1e-4\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    loss_train = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(\n",
    "        train_loader\n",
    "    ):  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        # test part\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        loss_train += criterion(out, data.y)\n",
    "\n",
    "    return correct / len(train_loader.dataset) * 100, loss_train / (i + 1)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(\n",
    "        loader\n",
    "    ):  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        loss += criterion(out, data.y)\n",
    "    return correct / len(loader.dataset) * 100, loss / (\n",
    "        i + 1\n",
    "    )  # Derive ratio of correct predictions. , proba\n",
    "\n",
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "for epoch in range(1, 401):\n",
    "    train_acc, train_loss = train()\n",
    "    # train_acc, train_loss = test(train_loader)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss = test(test_loader)[1].to(\"cpu\").detach().numpy()\n",
    "        print(\n",
    "            \"Epoch: {:03d}\".format(epoch),\n",
    "            \"loss_train: {:.4f}\".format(train_loss),\n",
    "            \"acc_train: {:.4f}\".format(train_acc),\n",
    "            \"loss_val: {:.4f}\".format(test_loss),\n",
    "            # \"acc_val: {:.4f}\".format(test_acc),\n",
    "        )\n",
    "        print(test(test_loader))\n",
    "        if min_val_loss > test_loss:\n",
    "            print(\n",
    "                f\"Validation Loss Decreased({min_val_loss:.6f}--->{test_loss:.6f}) \\t Saving The Model\"\n",
    "            )\n",
    "            min_val_loss = test_loss\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), \"saved_model_150m_params_GAT.pth\")\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Validation loss increased :(\")\n",
    "        print(f\"Epoch: {epoch:03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73bf9280-d04e-4ce3-8e3b-f4d4198809b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T15:53:07.716742Z",
     "iopub.status.busy": "2023-01-21T15:53:07.716123Z",
     "iopub.status.idle": "2023-01-21T15:53:07.720982Z",
     "shell.execute_reply": "2023-01-21T15:53:07.720480Z",
     "shell.execute_reply.started": "2023-01-21T15:53:07.716721Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81f7788a-8c94-497c-a68f-8dfd90a8ad0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:34:58.644410Z",
     "iopub.status.busy": "2023-01-21T22:34:58.644142Z",
     "iopub.status.idle": "2023-01-21T22:34:58.655416Z",
     "shell.execute_reply": "2023-01-21T22:34:58.654834Z",
     "shell.execute_reply.started": "2023-01-21T22:34:58.644392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (layer1): GCNConv(726, 64)\n",
       "  (layer2): GCNConv(64, 32)\n",
       "  (decoder): Linear(in_features=32, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"saved_model_150m_params_GAT.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0871f74-33ed-4032-b10a-b0c8acd0d090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T19:33:31.559642Z",
     "iopub.status.busy": "2023-01-21T19:33:31.558995Z",
     "iopub.status.idle": "2023-01-21T19:33:32.107022Z",
     "shell.execute_reply": "2023-01-21T19:33:32.106550Z",
     "shell.execute_reply.started": "2023-01-21T19:33:31.559621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.2208, dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader)[1].to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "800be3ae-319f-4e05-9edb-833c85970b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:35:04.795893Z",
     "iopub.status.busy": "2023-01-21T22:35:04.795635Z",
     "iopub.status.idle": "2023-01-21T22:35:04.808143Z",
     "shell.execute_reply": "2023-01-21T22:35:04.807521Z",
     "shell.execute_reply.started": "2023-01-21T22:35:04.795875Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    pred = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, _, data.batch)\n",
    "        out = softmax(out)\n",
    "        pred.append(out.to(\"cpu\").numpy())\n",
    "        # pred.append(out.argmax(dim=1))  # Use the class with highest probability.\n",
    "\n",
    "    return np.concatenate(pred, axis=0)  # Derive ratio of correct predictions. , proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9c2562d-305c-422f-95a5-44fcc4e6eb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:35:06.963396Z",
     "iopub.status.busy": "2023-01-21T22:35:06.963131Z",
     "iopub.status.idle": "2023-01-21T22:35:07.873371Z",
     "shell.execute_reply": "2023-01-21T22:35:07.872540Z",
     "shell.execute_reply.started": "2023-01-21T22:35:06.963378Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = predict(pred_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68761999-08ae-4dab-8747-a82dca5ffb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:35:34.249484Z",
     "iopub.status.busy": "2023-01-21T22:35:34.248979Z",
     "iopub.status.idle": "2023-01-21T22:35:34.261432Z",
     "shell.execute_reply": "2023-01-21T22:35:34.260904Z",
     "shell.execute_reply.started": "2023-01-21T22:35:34.249463Z"
    }
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba):\n",
    "    # Write predictions to a file\n",
    "    with open(\n",
    "        \"../Submissions/geometric_GCNcov_150_param__1.17_loss.csv\", \"w\"\n",
    "    ) as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f567b-2a08-436c-9f79-71f195effcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b56a2aa-9d94-4880-9ada-91778ebb889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526ddf0-c6d6-4da4-b908-082208350f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
